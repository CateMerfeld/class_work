{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 548 Homework #2: Data Preprocessing and Exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - KDD Definition\n",
    "\n",
    "Based on the following article: Fayyad, U., Piatetsky-Shapiro, G., and Smith, P. “From Data Mining to Knowledge Discovery in Databases”. AAAI Magazine. pp. 37-54. Fall, 1996, as well as on the Tan text and lecture content, answer the following questions:\n",
    "\n",
    "1. Define the term, **knowledge discovery in databases**.\n",
    "2. Briefly describe the steps of the knowledge discovery in databases process.\n",
    "3. Define the term, **data mining**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - Data Preprocessing\n",
    "\n",
    "Consider the following dataset:\n",
    "\n",
    "![](cs548_hw2_table1.png \"Table 1\")\n",
    "\n",
    "where each of the columns is defined below:\n",
    "* LIFE-EXP: Life Expectancy from UN Human Development Report (2003)\n",
    "* GDPPC: GDP per capita from figure published by the CIA (2006) in US$.\n",
    "* AC-S-ED: Access to secondary education rating from UNESCO (2002)\n",
    "* SWL (satisfaction with life) index calculated from data published by New Economics Foundation (2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Assuming that the missing value (marked with “?”) in GDPPC cannot be ignored, discuss 3 different alternatives to fill in that missing value. In each case, state what the selected value would be and the advantages and disadvantages of the approach. You may assume that the SWL attribute is the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: Impute with the column mean or median. \n",
    "If using the mean the filled value would be 18.2. If using median the filled value would be 11.1. Both mean and median can be good approaches in situations like this where the amount of missing data is limited. Mean can be susceptible to outliers, so median may be a better approach than mean, but I don't think either is ideal here since the results of either imputation would be inconsistent with the GDPPC for other countries with similar SWL to the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean GDPPC value is:  18.2\n",
      "The median GDPPC value is:  11.1\n"
     ]
    }
   ],
   "source": [
    "GDPPC_vals = [32.3, 34, 30.4, 10, 29.9, 8.3, 8.4, 31.5, 3.3, 0.9, 11.1]\n",
    "print('The mean GDPPC value is: ', round(np.mean(GDPPC_vals), 1))\n",
    "print('The median GDPPC value is: ', np.median(GDPPC_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B: Impute with **group** mean or median. \n",
    "\n",
    "To try and fill the value most accurately we might choose to focus only on the samples that are most similar to the sample we are trying to fill data for. Since we are interested in SWL, this could be a good feature to group the samples by. SWL is, in effect, a categorical variable, and we could group the USA with other countries with a SWL of 225-250. Since only two other countries are in this group (Germany and Mexico), the mean and median will be the same, 20.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean GDPPC value for the SWL 225-250 group is:  20.2\n",
      "The median GDPPC value for the SWL 225-250 group is:  20.2\n"
     ]
    }
   ],
   "source": [
    "print('The mean GDPPC value for the SWL 225-250 group is: ', round(np.mean(GDPPC_vals[2:4]), 1))\n",
    "print('The median GDPPC value for the SWL 225-250 group is: ', np.median(GDPPC_vals[2:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option C: Impute with value from predictive model.\n",
    "\n",
    "We could "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        COUNTRY  LIFE-EXP  GDPPC  AC-S-ED        SWL\n",
      "0   Switzerland      80.5   32.3     99.9  [250-275]\n",
      "1        Canada      80.0   34.0    102.6  [250-275]\n",
      "2           USA      77.4    0.0     94.6  [225-250]\n",
      "3       Germany      78.7   30.4     99.0  [225-250]\n",
      "4        Mexico      75.1   10.0     73.4  [225-250]\n",
      "5        France      79.5   29.9    108.7  [200-225]\n",
      "6      Thailand      70.0    8.3     79.0  [200-225]\n",
      "7        Brazil      70.5    8.4    103.2  [200-225]\n",
      "8         Japan      82.0   31.5    102.1  [200-225]\n",
      "9         India      63.3    3.3     49.9  [175-200]\n",
      "10     Ethiopia      47.6    0.9      5.2  [150-175]\n",
      "11       Russia      65.3   11.1     81.9  [125-150]\n"
     ]
    }
   ],
   "source": [
    "# Data from the table\n",
    "data = {\n",
    "    'COUNTRY': ['Switzerland', 'Canada', 'USA', 'Germany', 'Mexico', \n",
    "                'France', 'Thailand', 'Brazil', 'Japan', 'India', \n",
    "                'Ethiopia', 'Russia'],\n",
    "    'LIFE-EXP': [80.5, 80, 77.4, 78.7, 75.1, \n",
    "                 79.5, 70, 70.5, 82, 63.3, \n",
    "                 47.6, 65.3],\n",
    "    'GDPPC': [32.3, 34, 0, 30.4, 10, \n",
    "              29.9, 8.3, 8.4, 31.5, 3.3, \n",
    "              .9, 11.1],\n",
    "    'AC-S-ED': [99.9, 102.6, 94.6, 99, 73.4, \n",
    "                108.7, 79, 103.2, 102.1, 49.9,\n",
    "                5.2, 81.9],\n",
    "    'SWL': ['[250-275]', '[250-275]', '[225-250]', '[225-250]', '[225-250]', \n",
    "            '[200-225]', '[200-225]', '[200-225]', '[200-225]', '[175-200]', \n",
    "            '[150-175]', '[125-150]']\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Would you keep the attribute COUNTRY in your dataset when mining for patterns that predict the values for the SWL attribute? Explain your answer.\n",
    "3. Describe a reasonable transformation of the attribute COUNTRY so that the number of different values for that attribute is reduced to just 4.\n",
    "4. Discretize the AC-S-ED attribute by binning it into 4 equi-width intervals using unsupervised discretization. Perform this discretization by hand (i.e., do not use any software tools). Explain your answer.\n",
    "5. Discretize the AC-S-ED attribute by binning it into 4 equi-depth (= equal- frequency) intervals using unsupervised discretization. Perform this dis- cretization by hand (i.e., do not use any software). Explain your answer.\n",
    "6. Consider the following new approach to discretizing a numeric attribute: Given the mean and the standard deviation (sd) of the attribute values, bin the attribute values into the following intervals:\n",
    "$$[mean − (k + 1) × sd, mean − k × sd],\n",
    "∀k = . . . , −4, −3, −2, −1, 0, 1, 2, . . . (1)$$\n",
    ">> Assume that the mean of the attribute AC-S-ED above is 83 and that the\n",
    "standard deviation sd of this attribute is 30. Discretize AC-S-ED by hand\n",
    "using this new approach. Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Exploratory Data Analysis\n",
    "Consider Auto Dataset available on the Kaggle website. Load the dataset into\n",
    "a Jupyter notebook.\n",
    "* Make the attributes mpg, displacement, horsepower, weight, and acceler-\n",
    "ation continuous.\n",
    "* Make the attributes cylinders, model-year, and origin discrete;\n",
    "* Make the attribute car-name string.\n",
    "1. Start by familiarizing yourself with the dataset. Carefully look at the\n",
    "data directly (for this, use Python functionality to explore and visualize\n",
    "the data). Describe in your report your observations about what is good\n",
    "about this data (mention at least 2 different good things), and what is\n",
    "problematic about this data (mention at least 2 different bad things). If\n",
    "appropriate, include visualizations of those good/bad things.\n",
    "2. For the horsepower attribute:\n",
    "3\n",
    "(a) Calculate the percentiles in increments of 10, the mean, median,\n",
    "range, and variance.\n",
    "(b) Plot a histogram of the attribute using 10 or 20 bins.\n",
    "3. Use the discrete attributes as if they were continuous. For the set of all\n",
    "attributes in the dataset except for car-name, calculate 1) the covariance\n",
    "matrix and 2) the correlation matrix of these attributes. Construct a\n",
    "visualization of each of these matrices to more easily understand them.\n",
    "4. If you had to remove 2 of the attributes above from the dataset based on\n",
    "these two matrices, which attributes would you remove and why? Explain\n",
    "your answer.\n",
    "5. Dimensionality Reduction Apply Principal Components Analysis to\n",
    "reduce the dimensionality of the full dataset. How many dimensions does\n",
    "the original dataset contain? How many dimensions are obtained after\n",
    "PCA? How much of the variance do they explain? Include in your report\n",
    "the linear combinations that define the first new attribute (= component)\n",
    "obtained. Look at the results and elaborate on any interesting observations\n",
    "you can make about the results.\n",
    "Here are a couple tutorials plus a discussion of the mathematics of PCA\n",
    "that you may find helpful:\n",
    "* DataCamp PCA Tutorial\n",
    "* GeeksforGeeks PCA Tutorial\n",
    "* Mathematics behind PCA\n",
    "6. Attribute Transformation Convert the car-name attribute into a dis-\n",
    "crete attribute by changing each car-name into just the car brand (e.g.,\n",
    "toyota, ford, audi, ...). Using this modified dataset, run PCA in Python\n",
    "again as you did above and report any changes you observe in the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
