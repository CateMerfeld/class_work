{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of Day 79 Lecture 1 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CateMerfeld/class_work/blob/main/Copy_of_Day_79_Lecture_1_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuT0K8LDKm45"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "\n",
        "In this assignment, we will learn about convolutional neural networks. We will create a CNN and learn to classify image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMD7Nr8hKm47"
      },
      "source": [
        "In this lecture, we will use the image data generator to classify our data. The data is loaded below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6swIc-rGKm47"
      },
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "# from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization \n",
        "# from tensorflow.keras import backend as K\n",
        "# from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWBzWe88qtzB",
        "outputId": "d95a2aee-6562-4366-d031-e0c6e1f22d75"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxuDmAQlKm4-"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Data_Science_Course/Machine Learning/deep learning/dogs-vs-cats-processed/train/'\n",
        "validation_data_dir = '/content/drive/MyDrive/Data_Science_Course/Machine Learning/deep learning/dogs-vs-cats-processed/test'\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "batch_size = 80"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCfRV8VGKm5A"
      },
      "source": [
        "#This block of code is used to ensure the input shape is correct\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4x9el54Km5C"
      },
      "source": [
        "Define a train data generator with shear range of 0.3, zoom range of 0.1 and rescale to 1./255 (note that we must make 1 a float to produce a correct fraction). Use the ImageDataGenerator function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfKBxGZpKm5D"
      },
      "source": [
        "# Answer below:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=.2,\n",
        "    zoom_range=.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oQJZOxNKm5E"
      },
      "source": [
        "Define a test data generator that only rescales to 1./255. Use the ImageDataGenerator function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3XQZVLKm5F"
      },
      "source": [
        "# Answer below:\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0NCOxrCKm5G"
      },
      "source": [
        "The train generator and the test generator are defined below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDgonF6uKm5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca4e85b-ec9f-4730-bb47-1dd7a4117797"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    #shuffle=False,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 802 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lq09r31Km5K"
      },
      "source": [
        "We'll start with a simple model. In CNNs, we first convolve the to extract features and then we add the dense layers. \n",
        "\n",
        "Create a model with one layer of convolution of size 64, one layer of activation, one layer of max pooling with pool size (2,2) and then one flattening layer, one dense layer of unit size 64 with a ReLU activation and one dense output layer. The output layer should have a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqkMx3tKm5K"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEBJ5GXcKm5M"
      },
      "source": [
        "Compile the model using RMSprop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85uyZ1yTKm5M"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIKSpMe-Km5O"
      },
      "source": [
        "Fit the model using a fit generator. Use 50 epochs, 25 training steps and 15 validation steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFfKyhLzKm5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987c4dbc-6855-4fee-8f1d-c00942c22816"
      },
      "source": [
        "# Answer below:\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 25,\n",
        "    epochs=50,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 7.7220 - accuracy: 0.4967 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAZ1IeybKm5Q"
      },
      "source": [
        "Create a new model by adding an additional group of convolution, activation and max pooling layers before the flatten layer. Make the convolution layer of unit size 32. Keep everything else the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651SH4QGKm5Q"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfpSfgyKm5S"
      },
      "source": [
        "Fit and compile the model in the same way you did with the previous model. How did the results improve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5nPg_LmKm5S"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 25,\n",
        "    epochs=50,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgKv1_tCKm5U"
      },
      "source": [
        "Create a new model based on the model above. Add an additional dense layer of size 64 with a ReLU activation after the flatten layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlzEuIt3Km5U"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMg6k7tHKm5W"
      },
      "source": [
        "Fit and compile in the same way as above. Describe the difference in performance and speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqIEZC6YKm5W"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 25,\n",
        "    epochs=50,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRCyPKJfKm5Y"
      },
      "source": [
        "Fit and compile using the Adam optimizer. Describe the difference in performance between the Adam and RMSprop optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqzQbCl8Km5Z"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 25,\n",
        "    epochs=50,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drRBa855Km5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}